---

# ğŸ­ Interactive AI StoryTeller

### ğŸ§  A Creative AI App that Generates, Narrates & Exports Stories from Images

---

## ğŸ“Œ Overview

**AI StoryTeller** is an interactive project that combines **Computer Vision**, **Natural Language Processing**, and **Text-to-Speech** to create imaginative stories from uploaded images.
It uses **BLIP (Bootstrapped Language Image Pretraining)** for image captioning and **gTTS** for generating spoken narration, allowing users to **see, read, and hear** AI-generated stories.

This notebook/app showcases how AI can be used creatively to **interpret visual input** and **generate contextually meaningful narratives**, exported as both **audio** and **PDF storybooks**.

---

## ğŸš€ Features

* ğŸ–¼ **Image Captioning** with BLIP Transformer
* âœï¸ **Story Generation** based on image description
* ğŸ”Š **Text-to-Speech Narration** via Google TTS
* ğŸ“„ **Automatic PDF Storybook Creation** (with embedded images)
* ğŸŒ **Streamlit App Integration** for interactive use
* âš¡ **Ngrok Tunnel Support** for Colab-based deployment

---

## ğŸ›  Technologies Used

| Category             | Libraries / Tools                                               |
| -------------------- | --------------------------------------------------------------- |
| **Core AI/ML**       | `transformers`, `BLIPProcessor`, `BLIPForConditionalGeneration` |
| **Audio Generation** | `gTTS`                                                          |
| **UI / App**         | `streamlit`, `pyngrok`                                          |
| **PDF Generation**   | `reportlab`                                                     |
| **Image Handling**   | `Pillow (PIL)`                                                  |
| **Environment**      | `Python 3.x`, `Google Colab`                                    |

---

## âš™ Installation

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/MeenalSinha/AI_StoryTeller.git
cd AI_StoryTeller

# 2ï¸âƒ£ (Optional) Create a virtual environment
python -m venv venv
source venv/bin/activate      # On macOS/Linux
venv\Scripts\activate         # On Windows

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
```

---

## â–¶ Usage

### ğŸ’¡ Option 1: Run in Google Colab

Open the notebook:

```bash
AI_StoryTeller.ipynb
```

Follow the steps:

1. Upload an image
2. Generate a description using BLIP
3. Convert it into a short story
4. Listen to the narration
5. Export as a PDF storybook

---

### ğŸ’» Option 2: Run the Streamlit App

```bash
streamlit run app_streamlit_story.py
```

Then open the public URL provided by **ngrok** to interact with the live app.

---

## ğŸ“Š Workflow

1. **Upload Image** â†’ via Streamlit or notebook cell
2. **Generate Caption** â†’ using BLIP model (`Salesforce/blip-image-captioning-base`)
3. **Create Story** â†’ based on AI-generated caption
4. **Narrate Story** â†’ with `gTTS` (Text-to-Speech)
5. **Export PDF** â†’ image + storybook saved locally

---

## ğŸ“‚ File Structure

```
AI_StoryTeller/
â”‚
â”œâ”€â”€ app_streamlit_story.py      # Streamlit app script
â”œâ”€â”€ AI_StoryTeller.ipynb        # Colab notebook
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ story_outputs/              # Generated PDFs & audio
â””â”€â”€ assets/                     # Sample images
```

---

## ğŸ§ Example Output

**Input Image:** Uploaded by user
**Generated Story:**

> â€œAs the sun set beyond the mountains, the traveler paused, feeling the warmth fade into whispers of twilightâ€¦â€

**Audio Output:** Generated MP3 narration
**Exported File:** `Story_Output.pdf`

---

## ğŸ‘¨â€ğŸ’» Author

**Meenal Sinha**
ğŸ“§ [meenal.sinha09@gmail.com](mailto:meenal.sinha09@gmail.com)
ğŸŒ [GitHub â€“ MeenalSinha](https://github.com/MeenalSinha)

---
